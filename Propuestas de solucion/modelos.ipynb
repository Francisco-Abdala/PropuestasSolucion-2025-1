{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de archivo gracias a la librería pandas\n",
    "archivo = pd.read_csv(\"alzheimers_disease_data.csv\")\n",
    "archivo = archivo.drop(\"DoctorInCharge\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Naive bayes con Gauss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "# Separar variable objetivo de los demás atributos\n",
    "X = archivo.drop('Diagnosis', axis=1)\n",
    "y = archivo['Diagnosis']\n",
    "\n",
    "\n",
    "#División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Balancear el conjunto de entrenamiento\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "#Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train_balanced) \n",
    "\n",
    "y_pred = nb_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_NB = accuracy_score(y_test, y_pred)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred,labels=[1,0] )\n",
    "\n",
    "#Reporte\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(class_report)\n",
    "\n",
    "#Matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',\n",
    "           xticklabels=['Positivo', 'Negativo'],\n",
    "           yticklabels=['Positivo', 'Negativo'])\n",
    "plt.title('Matriz de Confusión - GaussianNB')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predicho')\n",
    "plt.show()\n",
    "\n",
    "precision_NB = precision_score(y_test, y_pred)\n",
    "recall_NB = recall_score(y_test, y_pred)\n",
    "f1_nb = f1_score(y_test, y_pred)\n",
    "tn_nb, fp_nb, fn_nb, tp_nb = conf_matrix.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Naive Bayes con Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Separar variable objetivo de los demás atributos\n",
    "X = archivo.drop('Diagnosis', axis=1)\n",
    "y = archivo['Diagnosis']\n",
    "\n",
    "\n",
    "#División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Balancear el conjunto de entrenamiento\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "#Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced) \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Entrenar modelo.\n",
    "Bernoulli_model = BernoulliNB()\n",
    "\n",
    "Bernoulli_model.fit(X_train_scaled, y_train_balanced) \n",
    "\n",
    "y_pred = Bernoulli_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_BNB = accuracy_score(y_test, y_pred)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=[1, 0])\n",
    "\n",
    "#Reporte de clasificación\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(class_report)\n",
    "\n",
    "#Matriz de confusión con orden modificado\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Positivo', 'Negativo'],  \n",
    "            yticklabels=['Positivo', 'Negativo'])  \n",
    "plt.title('Matriz de Confusión - Bernoulli')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predicho')\n",
    "plt.show()\n",
    "\n",
    "precision_BNB = precision_score(y_test, y_pred)\n",
    "recall_BNB = recall_score(y_test, y_pred)\n",
    "f1_bnb = f1_score(y_test, y_pred)\n",
    "tn_bnb, fp_bnb, fn_bnb, tp_bnb = conf_matrix.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#Separar variable objetivo de los demás atributos\n",
    "X = archivo.drop('Diagnosis', axis=1)\n",
    "y = archivo['Diagnosis']\n",
    "\n",
    "#Separar datos de entrenamiento y de testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Balancear conjunto de entrenamiento\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "#Estandarizar data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "k_range = range(1, 51)\n",
    "scores = []\n",
    "\n",
    "#Buscar mejor \"n\" y guardar sus valores para posteriormente graficarlos\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train_balanced)\n",
    "    y_pred_k = knn.predict(X_test_scaled)\n",
    "    scores.append(accuracy_score(y_test, y_pred_k))\n",
    "\n",
    "#Muestra en un gráfico el desempeño de KNN (MEJORADO)\n",
    "plt.figure(figsize=(20, 8))  # Tamaño más manejable\n",
    "plt.plot(k_range, scores, marker='o', linewidth=2, markersize=4)\n",
    "plt.title('Exactitud del modelo para diferentes valores de k', fontsize=14)\n",
    "plt.xlabel('Valor de k', fontsize=12)\n",
    "plt.ylabel('Exactitud', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "# Mostrar solo cada 5 valores para mejor legibilidad\n",
    "plt.xticks(k_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_score = max(scores)\n",
    "best_k = k_range[scores.index(best_score)]\n",
    "\n",
    "#Mostrar información del mejor k\n",
    "print(f\"Mejor k encontrado: {best_k}\")\n",
    "print(f\"Exactitud correspondiente: {best_score:.4f}\")\n",
    "\n",
    "#Verificar si hay múltiples k con la misma exactitud máxima\n",
    "best_k_candidates = [k for k, score in zip(k_range, scores) if score == best_score]\n",
    "if len(best_k_candidates) > 1:\n",
    "    print(f\"Otros k con la misma exactitud: {best_k_candidates}\")\n",
    "    print(f\"Se eligió k={best_k} (el más pequeño para mayor simplicidad)\")\n",
    "\n",
    "#Entrena al modelo con el mejor K posible\n",
    "final_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "final_knn_model.fit(X_train_scaled, y_train_balanced)\n",
    "final_y_pred = final_knn_model.predict(X_test_scaled)\n",
    "\n",
    "#Métricas del modelo final\n",
    "final_accuracy_KNN = accuracy_score(y_test, final_y_pred)\n",
    "print(f\"\\nExactitud del modelo final: {final_accuracy_KNN:.4f}\")\n",
    "\n",
    "#Matriz de confusión para el modelo final.\n",
    "final_conf_matrix = confusion_matrix(y_test, final_y_pred, labels=[1, 0])\n",
    "\n",
    "#Visualizar la matriz de confusión final\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(final_conf_matrix, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Positivo', 'Negativo'],\n",
    "            yticklabels=['Positivo', 'Negativo'])\n",
    "plt.title(f'Matriz de Confusión - KNN (k={best_k})')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predicho')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación final\n",
    "print(\"\\nReporte de clasificación final:\")\n",
    "print(classification_report(y_test, final_y_pred))\n",
    "\n",
    "precision_KNN = precision_score(y_test, y_pred)\n",
    "recall_KNN = recall_score(y_test, y_pred)\n",
    "f1_knn = f1_score(y_test, y_pred)\n",
    "tn_knn, fp_knn, fn_knn, tp_knn = final_conf_matrix.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de árboles de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#Separar variable objetivo de los demás atributos\n",
    "X = archivo.drop('Diagnosis', axis=1)\n",
    "y = archivo['Diagnosis']\n",
    "\n",
    "#Separar datos de entrenamiento y de testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Balancear conjunto de entrenamiento\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "#Estandarizar data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Optimizar max_depth (profundidad del árbol)\n",
    "depth_range = range(1, 21)\n",
    "depth_scores = []\n",
    "\n",
    "for depth in depth_range:\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    tree.fit(X_train_scaled, y_train_balanced)\n",
    "    y_pred = tree.predict(X_test_scaled)\n",
    "    depth_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Gráfico para max_depth\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(depth_range, depth_scores, marker='o', linewidth=2, markersize=4)\n",
    "plt.title('Exactitud vs Max Depth', fontsize=12)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(depth_range)\n",
    "\n",
    "#Optimizar min_samples_split (Valor mínimo para separar un nodo interno)\n",
    "split_range = range(2, 21)\n",
    "split_scores = []\n",
    "\n",
    "for split in split_range:\n",
    "    tree = DecisionTreeClassifier(min_samples_split=split, random_state=42)\n",
    "    tree.fit(X_train_scaled, y_train_balanced)\n",
    "    y_pred = tree.predict(X_test_scaled)\n",
    "    split_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Gráfico para min_samples_split\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(split_range, split_scores, marker='o', linewidth=2, markersize=4, color='orange')\n",
    "plt.title('Exactitud vs Min Samples Split', fontsize=12)\n",
    "plt.xlabel('Min Samples Split')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(split_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Optimizar min_samples_leaf (Valor mínimo para ser un nodo hoja)\n",
    "leaf_range = range(1, 11)\n",
    "leaf_scores = []\n",
    "\n",
    "for leaf in leaf_range:\n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=leaf, random_state=42)\n",
    "    tree.fit(X_train_scaled, y_train_balanced)\n",
    "    y_pred = tree.predict(X_test_scaled)\n",
    "    leaf_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Gráfico para min_samples_leaf\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(leaf_range, leaf_scores, marker='o', linewidth=2, markersize=4, color='green')\n",
    "plt.title('Exactitud vs Min Samples Leaf', fontsize=12)\n",
    "plt.xlabel('Min Samples Leaf')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(leaf_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Mejor max_depth\n",
    "best_depth_score = max(depth_scores)\n",
    "best_depth = depth_range[depth_scores.index(best_depth_score)]\n",
    "#Mejor min_samples_split\n",
    "best_split_score = max(split_scores)\n",
    "best_split = split_range[split_scores.index(best_split_score)]\n",
    "#Mejor min_samples_leaf\n",
    "best_leaf_score = max(leaf_scores)\n",
    "best_leaf = leaf_range[leaf_scores.index(best_leaf_score)]\n",
    "\n",
    "#Modelo a entrenar\n",
    "final_tree = DecisionTreeClassifier(\n",
    "    max_depth=best_depth,\n",
    "    min_samples_split=best_split,\n",
    "    min_samples_leaf=best_leaf,\n",
    "    random_state=42\n",
    ")\n",
    "final_tree.fit(X_train_scaled, y_train_balanced)\n",
    "final_y_pred = final_tree.predict(X_test_scaled)\n",
    "\n",
    "#Métricas del modelo\n",
    "final_accuracy_TREE = accuracy_score(y_test, final_y_pred)\n",
    "print(f\"\\nExactitud del modelo final: {final_accuracy_TREE:.4f}\")\n",
    "\n",
    "final_conf_matrix = confusion_matrix(y_test, final_y_pred, labels=[1, 0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(final_conf_matrix, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Positivo', 'Negativo'],\n",
    "            yticklabels=['Positivo', 'Negativo'])\n",
    "plt.title(f'Matriz de Confusión - Árbol de Decisión\\n(depth={best_depth}, split={best_split}, leaf={best_leaf})')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predicho')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación final\n",
    "print(\"\\nReporte de clasificación final:\")\n",
    "print(classification_report(y_test, final_y_pred, zero_division=0))\n",
    "\n",
    "plot_tree(final_tree,filled=True)\n",
    "plt.show()\n",
    "\n",
    "precision_TREE = precision_score(y_test, y_pred)\n",
    "recall_TREE = recall_score(y_test, y_pred)\n",
    "f1_tree = f1_score(y_test, y_pred)\n",
    "tn_tree, fp_tree, fn_tree, tp_tree = final_conf_matrix.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#Separar variable objetivo de los demás atributos\n",
    "X = archivo.drop('Diagnosis', axis=1)\n",
    "y = archivo['Diagnosis']\n",
    "\n",
    "#Separar datos de entrenamiento y de testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Balancear conjunto de entrenamiento\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "#Estandarizar data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Optimizar n_estimators\n",
    "range_estimators = range(10, 201, 20)\n",
    "score_estimators = []\n",
    "\n",
    "for estimator in range_estimators:\n",
    "    forest = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "    forest.fit(X_train_scaled, y_train_balanced) \n",
    "    y_pred = forest.predict(X_test_scaled)        \n",
    "    score_estimators.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Optimizar max_depth\n",
    "depth_range = [None] + list(range(5, 21, 2))\n",
    "depth_scores = []\n",
    "\n",
    "for depth in depth_range:\n",
    "    forest = RandomForestClassifier(max_depth=depth, random_state=42)\n",
    "    forest.fit(X_train_scaled, y_train_balanced)\n",
    "    y_pred = forest.predict(X_test_scaled)\n",
    "    depth_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#Optimizar min_samples_split\n",
    "split_range = range(2, 11)\n",
    "split_scores = []\n",
    "\n",
    "for split in split_range:\n",
    "    forest = RandomForestClassifier(min_samples_split=split, random_state=42)\n",
    "    forest.fit(X_train_scaled, y_train_balanced)\n",
    "    y_pred = forest.predict(X_test_scaled)\n",
    "    split_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Gráfico n_estimators\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range_estimators, score_estimators, marker='o', linewidth=2, markersize=4)\n",
    "plt.title('Exactitud vs N_Estimators', fontsize=12)\n",
    "plt.xlabel('N_Estimators')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(10, 201, 40))  # Mostrar cada 40\n",
    "#Gráfico max_depth\n",
    "plt.subplot(1, 3, 2)\n",
    "depth_labels = ['None'] + [str(d) for d in depth_range[1:]]\n",
    "plt.plot(range(len(depth_range)), depth_scores, marker='o', linewidth=2, markersize=4, color='orange')\n",
    "plt.title('Exactitud vs Max_Depth', fontsize=12)\n",
    "plt.xlabel('Max_Depth')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(len(depth_range)), depth_labels, rotation=45)\n",
    "#Gráfico min_samples_split\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(split_range, split_scores, marker='o', linewidth=2, markersize=4, color='green')\n",
    "plt.title('Exactitud vs Min_Samples_Split', fontsize=12)\n",
    "plt.xlabel('Min_Samples_Split')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(split_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Mejor n_estimators\n",
    "best_estimator_score = max(score_estimators)\n",
    "best_estimator = list(range_estimators)[score_estimators.index(best_estimator_score)]\n",
    "#Mejor max_depth\n",
    "best_depth_score = max(depth_scores)\n",
    "best_depth = depth_range[depth_scores.index(best_depth_score)]\n",
    "#Mejor min_samples_split\n",
    "best_split_score = max(split_scores)\n",
    "best_split = split_range[split_scores.index(best_split_score)]\n",
    "\n",
    "final_forest = RandomForestClassifier(\n",
    "    n_estimators=best_estimator,\n",
    "    max_depth=best_depth,\n",
    "    min_samples_split=best_split,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_forest.fit(X_train_scaled, y_train_balanced)\n",
    "final_y_pred = final_forest.predict(X_test_scaled)\n",
    "\n",
    "#Métricas del modelo final\n",
    "final_accuracy_RF = accuracy_score(y_test, final_y_pred)\n",
    "print(f\"\\nExactitud del modelo final: {final_accuracy_RF:.4f}\")\n",
    "\n",
    "#Matriz de confusión\n",
    "final_conf_matrix = confusion_matrix(y_test, final_y_pred, labels=[1, 0])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(final_conf_matrix, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Positivo', 'Negativo'],\n",
    "            yticklabels=['Positivo', 'Negativo'])\n",
    "plt.title(f'Matriz de Confusión - Random Forest\\n(estimators={best_estimator}, depth={best_depth}, split={best_split})')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Predicho')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación final\n",
    "print(\"\\nReporte de clasificación final:\")\n",
    "print(classification_report(y_test, final_y_pred, zero_division=0))\n",
    "\n",
    "precision_RF = precision_score(y_test, y_pred)\n",
    "recall_RF = recall_score(y_test, y_pred)\n",
    "f1_rf = f1_score(y_test, y_pred)\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = final_conf_matrix.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas ROC de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "#Crear la gráfica de la curva ROC de Gaussian Naive Bayes \n",
    "y_pred_proba = nb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "auc_score_NB = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_score_NB:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Línea de referencia (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Gaussian Naive Bayes')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "#Crear la gráfica de la curva ROC de Bernoulli Naive Bayes\n",
    "y_pred_proba = Bernoulli_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "auc_score_BBN = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_score_BBN:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Línea de referencia (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Bernoulli Naive Bayes')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "#Crear la gráfica de la curva ROC de KNN\n",
    "y_pred_proba = final_knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "auc_score_KNN = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_score_KNN:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Línea de referencia (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - KNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "#Crear la gráfica de la curva ROC de Árbol de decisión\n",
    "y_pred_proba = final_tree.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "auc_score_TREE= roc_auc_score(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_score_TREE:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Línea de referencia (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Árbol de decisión')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "#Crear la gráfica de la curva ROC de Random Forest\n",
    "y_pred_proba = final_forest.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "auc_score_RF = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_score_RF:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Línea de referencia (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de los valores importantes de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>AUC-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.839535</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>235.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.853488</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.849673</td>\n",
       "      <td>0.804954</td>\n",
       "      <td>237.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.895189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.922559</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.859064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.972093</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.947712</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>270.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.976865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.922559</td>\n",
       "      <td>271.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.981029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Accuracy  Precision    Recall  F1-Score  \\\n",
       "Gaussian Naive Bayes   0.839535   0.750000  0.823529  0.785047   \n",
       "Bernoulli Naive Bayes  0.853488   0.764706  0.849673  0.804954   \n",
       "KNN                    0.790698   0.951389  0.895425  0.922559   \n",
       "Decision Tree          0.972093   0.923567  0.947712  0.935484   \n",
       "Random Forest          0.953488   0.951389  0.895425  0.922559   \n",
       "\n",
       "                       True Positives  True Negatives  False Positives  \\\n",
       "Gaussian Naive Bayes            235.0           126.0             27.0   \n",
       "Bernoulli Naive Bayes           237.0           130.0             23.0   \n",
       "KNN                             237.0           103.0             50.0   \n",
       "Decision Tree                   270.0           148.0              5.0   \n",
       "Random Forest                   271.0           139.0             14.0   \n",
       "\n",
       "                       False Negatives  AUC-score  \n",
       "Gaussian Naive Bayes              42.0   0.895000  \n",
       "Bernoulli Naive Bayes             40.0   0.895189  \n",
       "KNN                               40.0   0.859064  \n",
       "Decision Tree                      7.0   0.976865  \n",
       "Random Forest                      6.0   0.981029  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive_Bayes_dict = {\n",
    "    'Accuracy': accuracy_NB,\n",
    "    'Precision': precision_NB,\n",
    "    'Recall': recall_NB,\n",
    "    'F1-Score': f1_nb,\n",
    "    'True Positives': tp_nb,\n",
    "    'True Negatives': tn_nb,\n",
    "    'False Positives': fp_nb,\n",
    "    'False Negatives': fn_nb,\n",
    "    'AUC-score': auc_score_NB\n",
    "}\n",
    "Naive_Bayes_dict2 = {\n",
    "    'Accuracy': accuracy_BNB,\n",
    "    'Precision': precision_BNB,\n",
    "    'Recall': recall_BNB,\n",
    "    'F1-Score': f1_bnb,\n",
    "    'True Positives': tp_bnb,\n",
    "    'True Negatives': tn_bnb,\n",
    "    'False Positives': fp_bnb,\n",
    "    'False Negatives': fn_bnb,\n",
    "    'AUC-score': auc_score_BBN\n",
    "}\n",
    "\n",
    "KNN = {\n",
    "    'Accuracy': final_accuracy_KNN,\n",
    "    'Precision': precision_KNN,\n",
    "    'Recall': recall_KNN,\n",
    "    'F1-Score': f1_knn,\n",
    "    'True Positives': tp_knn,\n",
    "    'True Negatives': tn_knn,\n",
    "    'False Positives': fp_knn,\n",
    "    'False Negatives': fn_knn,\n",
    "    'AUC-score': auc_score_KNN\n",
    "}\n",
    "TREE = {\n",
    "    'Accuracy': final_accuracy_TREE,\n",
    "    'Precision': precision_TREE,\n",
    "    'Recall': recall_TREE,\n",
    "    'F1-Score': f1_tree,\n",
    "    'True Positives': tp_tree,\n",
    "    'True Negatives': tn_tree,\n",
    "    'False Positives': fp_tree,\n",
    "    'False Negatives': fn_tree,\n",
    "    'AUC-score': auc_score_TREE,\n",
    "}\n",
    "RF = {\n",
    "    'Accuracy': final_accuracy_RF,\n",
    "    'Precision': precision_RF,\n",
    "    'Recall': recall_RF,\n",
    "    'F1-Score': f1_rf,\n",
    "    'True Positives': tp_rf,\n",
    "    'True Negatives': tn_rf,\n",
    "    'False Positives': fp_rf,\n",
    "    'False Negatives': fn_rf,\n",
    "    'AUC-score': auc_score_RF\n",
    "}\n",
    "\n",
    "resume = pd.DataFrame({\n",
    "    'Gaussian Naive Bayes': pd.Series(Naive_Bayes_dict),\n",
    "    'Bernoulli Naive Bayes': pd.Series(Naive_Bayes_dict2),\n",
    "    'KNN': pd.Series(KNN),\n",
    "    'Decision Tree': pd.Series(TREE),\n",
    "    'Random Forest': pd.Series(RF)\n",
    "})\n",
    "\n",
    "resume.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos por métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_grouped_metrics(df):\n",
    "    \"\"\"Crear un gráfico de barras separado para cada métrica\"\"\"\n",
    "    metrics = df.index.tolist()\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        #Crear una nueva figura para cada métrica\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        #Datos para la métrica actual\n",
    "        values = df.loc[metric].values\n",
    "        models = df.columns.tolist()\n",
    "        \n",
    "        bars = plt.bar(models, values, alpha=0.8)\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(models)))\n",
    "        for bar, color in zip(bars, colors):\n",
    "            bar.set_color(color)\n",
    "\n",
    "        for j, (model, value) in enumerate(zip(models, values)):\n",
    "            if pd.notna(value):  # Solo si el valor no es NaN\n",
    "                plt.text(j, value + max(values)*0.01, f'{value:.3f}',\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.title(f'{metric}', fontweight='bold', fontsize=16)\n",
    "        plt.ylabel('Valor', fontsize=12)\n",
    "        plt.xlabel('Modelos', fontsize=12)\n",
    "        plt.ylim(0, max(values) * 1.1 if max(values) > 0 else 1)\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_grouped_metrics(resume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
